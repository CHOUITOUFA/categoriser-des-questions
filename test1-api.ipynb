{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbd8c980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohaw\\AppData\\Local\\Temp\\ipykernel_11956\\3127415297.py:13: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    }
   ],
   "source": [
    "#python librairies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn.metrics as metrics\n",
    "from IPython.core.display import display, HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2000f1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Score</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4795928</th>\n",
       "      <td>[check, element, exists]</td>\n",
       "      <td>[possible, duplicate, exists, function, jquery...</td>\n",
       "      <td>31</td>\n",
       "      <td>[javascript, jquery]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796305</th>\n",
       "      <td>[internet, explorer, send, http, post, body, a...</td>\n",
       "      <td>[able, reliably, recreate, following, scenario...</td>\n",
       "      <td>115</td>\n",
       "      <td>[javascript]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797373</th>\n",
       "      <td>[eval, point]</td>\n",
       "      <td>[official, documentation, regarding, function,...</td>\n",
       "      <td>6</td>\n",
       "      <td>[php]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797418</th>\n",
       "      <td>[tracking, object, allocation, python]</td>\n",
       "      <td>[method, override, allow, use, print, statemen...</td>\n",
       "      <td>10</td>\n",
       "      <td>[python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797444</th>\n",
       "      <td>[weird, error, installing, android, app]</td>\n",
       "      <td>[intellij, idea, exported, signed, application...</td>\n",
       "      <td>7</td>\n",
       "      <td>[android]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Title  \\\n",
       "Id                                                           \n",
       "4795928                           [check, element, exists]   \n",
       "4796305  [internet, explorer, send, http, post, body, a...   \n",
       "4797373                                      [eval, point]   \n",
       "4797418             [tracking, object, allocation, python]   \n",
       "4797444           [weird, error, installing, android, app]   \n",
       "\n",
       "                                                      Body  Score  \\\n",
       "Id                                                                  \n",
       "4795928  [possible, duplicate, exists, function, jquery...     31   \n",
       "4796305  [able, reliably, recreate, following, scenario...    115   \n",
       "4797373  [official, documentation, regarding, function,...      6   \n",
       "4797418  [method, override, allow, use, print, statemen...     10   \n",
       "4797444  [intellij, idea, exported, signed, application...      7   \n",
       "\n",
       "                         Tags  \n",
       "Id                             \n",
       "4795928  [javascript, jquery]  \n",
       "4796305          [javascript]  \n",
       "4797373                 [php]  \n",
       "4797418              [python]  \n",
       "4797444             [android]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the cleaned dataset\n",
    "\n",
    "#Importation data\n",
    "data = pd.read_csv(\"StackOverflow_cleaned.csv\", sep=\";\",\n",
    "                   index_col=0,\n",
    "                   converters={\"Title\": literal_eval,\n",
    "                               \"Body\": literal_eval,\n",
    "                               \"Tags\": literal_eval})\n",
    "data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2ea6c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['Title'] + data['Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28047ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tags: 50\n"
     ]
    }
   ],
   "source": [
    "# transform target tags\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(data.Tags)\n",
    "y_mlb = mlb.transform(data.Tags)\n",
    "print(\"Number of Tags:\", len(mlb.classes_))\n",
    "#\n",
    "# data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.text,\\\n",
    "                    y_mlb, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab0508c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 14\u001b[0m\n\u001b[0;32m      4\u001b[0m final_model \u001b[38;5;241m=\u001b[39m Pipeline([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtfidf\u001b[39m\u001b[38;5;124m'\u001b[39m, TfidfVectorizer(analyzer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m                              max_df\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.98\u001b[39m,\n\u001b[0;32m      6\u001b[0m                              min_df\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m                              lowercase\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)),\n\u001b[0;32m     11\u001b[0m                         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m, OneVsRestClassifier(LogisticRegression()))])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#fit model\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m final_model\u001b[38;5;241m.\u001b[39mfit(X_train,y_train)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#prediction and score\u001b[39;00m\n\u001b[0;32m     17\u001b[0m y_score \u001b[38;5;241m=\u001b[39m final_model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py:401\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \n\u001b[0;32m    377\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    400\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 401\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps)\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py:359\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    357\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    360\u001b[0m     cloned_transformer,\n\u001b[0;32m    361\u001b[0m     X,\n\u001b[0;32m    362\u001b[0m     y,\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    364\u001b[0m     message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    365\u001b[0m     message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(step_idx),\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps[name],\n\u001b[0;32m    367\u001b[0m )\n\u001b[0;32m    368\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\sklearn\\pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 893\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    895\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:2133\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m   2127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2128\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2129\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2130\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2131\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2132\u001b[0m )\n\u001b[1;32m-> 2133\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_transform(raw_documents)\n\u001b[0;32m   2134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2135\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2136\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1388\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1380\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1381\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1382\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1384\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1385\u001b[0m             )\n\u001b[0;32m   1386\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_count_vocab(raw_documents, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_vocabulary_)\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1391\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1275\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1273\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[0;32m   1274\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1275\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m analyze(doc):\n\u001b[0;32m   1276\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1277\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32m~\\anaconda3\\anaconda\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:113\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    111\u001b[0m     doc \u001b[38;5;241m=\u001b[39m preprocessor(doc)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     doc \u001b[38;5;241m=\u001b[39m tokenizer(doc)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ngrams \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop_words \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#Piple of the final modèle\n",
    "# define model\n",
    "# tfidf features\n",
    "final_model = Pipeline([('tfidf', TfidfVectorizer(analyzer=\"word\",\n",
    "                             max_df=.98,\n",
    "                             min_df= 2,\n",
    "                             tokenizer=None,\n",
    "                             preprocessor=' '.join,\n",
    "                             stop_words=None,\n",
    "                             lowercase=False)),\n",
    "                        ('lr', OneVsRestClassifier(LogisticRegression()))])\n",
    "\n",
    "#fit model\n",
    "final_model.fit(X_train,y_train)\n",
    "\n",
    "#prediction and score\n",
    "y_score = final_model.predict_proba(X_test)\n",
    "print('Score ROC_AUC:', metrics.roc_auc_score(y_test, y_score,multi_class=\"ovr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4d02ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "\n",
    "#Modèle serialisation\n",
    "dump(final_model, open(\"final_model.pkl\",\"wb\"))\n",
    "dump(mlb, open(\"mlb.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab91cbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "final_model=load(open(\"final_model.pkl\",\"rb\"))\n",
    "mlb=load(open(\"mlb.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19d142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with one text\n",
    "text = ['python','model','c#','class','C++']\n",
    "#threshold for labels with scores, fitted from the ROC \n",
    "threshold = 0.11 \n",
    "y_pred = final_model.predict_proba(np.array([text,]))\n",
    "tag = mlb.inverse_transform((y_pred>threshold)*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec06dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tags proposés:', tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a334f575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925f11ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d3c0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c5145a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b3ef0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d2619a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c28878a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b96db3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4be8d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.py — Contient le code permettant au modèle d’apprentissage automatique de prédire les ventes du troisième mois en fonction des ventes des deux premiers mois.\n",
    "app.py — Il contient les API Flask qui reçoivent les détails des ventes via une interface graphique ou des appels d’API, calculent la valeur prédite en fonction de notre modèle et la renvoient.\n",
    "request.py — Cette option utilise le module requests pour appeler les API définies dans app.py et affiche la valeur renvoyée.\n",
    "HTML/CSS — Contient le modèle HTML et le style CSS pour permettre à l’utilisateur d’entrer les détails des ventes et affiche les ventes prévues au cours du troisième mois.\n",
    "\n",
    "Où est le code?\n",
    "Sans trop tarder, commençons par le code. Le projet complet sur github peut être trouvé ici.\n",
    "\n",
    "Commençons par créer le frontal à l’aide de HTML pour que l’utilisateur puisse entrer les valeurs. Il y a trois champs qui doivent être remplis par l’utilisateur: taux d’intérêt, ventes au premier mois et ventes au deuxième mois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff8717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "<!DOCTYPE html>\n",
    "<html >\n",
    "<head>\n",
    "  <meta charset=\"UTF-8\">\n",
    "  <title>Deployment Tutorial 1</title>\n",
    "  <link href='https://fonts.googleapis.com/css?family=Pacifico' rel='stylesheet' type='text/css'>\n",
    "<link href='https://fonts.googleapis.com/css?family=Arimo' rel='stylesheet' type='text/css'>\n",
    "<link href='https://fonts.googleapis.com/css?family=Hind:300' rel='stylesheet' type='text/css'>\n",
    "<link href='https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300' rel='stylesheet' type='text/css'>\n",
    "<link rel=\"stylesheet\" href=\"{{ url_for('static', filename='css/style.css') }}\">\n",
    "  \n",
    "</head>\n",
    "\n",
    "<body style=\"background: #000;\">\n",
    " <div class=\"login\">\n",
    "<h1>Sales Forecasting</h1>\n",
    "\n",
    "     <!-- Main Input For Receiving Query to our ML -->\n",
    "    <form action=\"{{ url_for('predict')}}\"method=\"post\">\n",
    "    <input type=\"text\" name=\"rate\" placeholder=\"rate\" required=\"required\" />\n",
    "        <input type=\"text\" name=\"sales in first month\" placeholder=\"sales in first month\" required=\"required\" />\n",
    "<input type=\"text\" name=\"sales in second month\" placeholder=\"sales in second month\" required=\"required\" />\n",
    "        <button type=\"submit\" class=\"btn btn-primary btn-block btn-large\">Predict sales in third month</button>\n",
    "    </form>\n",
    "\n",
    "   <br>\n",
    "   <br>\n",
    "   {{ prediction_text }}\n",
    "\n",
    " </div>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16b42d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@import url(https://fonts.googleapis.com/css?family=Open+Sans);\n",
    "\n",
    "html { width: 100%; height:100%; overflow:hidden; }\n",
    "\n",
    "body { \n",
    "   width: 100%;\n",
    "   height:100%;\n",
    "   font-family: 'Helvetica';\n",
    "   background: #000;\n",
    "   color: #fff; \n",
    "     font-size: 24px;\n",
    "    text-align:center;\n",
    "   letter-spacing:1.4px;\n",
    "\n",
    "}\n",
    ".login { \n",
    "    position: absolute;\n",
    "    top: 40%;\n",
    "   left: 50%;\n",
    "     margin: -150px 0 0 -150px;\n",
    "   width:400px;\n",
    "   height:400px;\n",
    "}\n",
    "\n",
    ".login h1 { color: #fff; text-shadow: 0 0 10px rgba(0,0,0,0.3); letter-spacing:1px; text-align:center; }\n",
    "\n",
    "input { \n",
    "   width: 100%; \n",
    "   margin-bottom: 10px; \n",
    "   background: rgba(0,0,0,0.3);\n",
    "   border: none;\n",
    "   outline: none;\n",
    "   padding: 10px;\n",
    "   font-size: 13px;\n",
    "   color: #fff;\n",
    "   text-shadow: 1px 1px 1px rgba(0,0,0,0.3);\n",
    "   border: 1px solid rgba(0,0,0,0.3);\n",
    "   border-radius: 4px;\n",
    "   box-shadow: inset 0 -5px 45px rgba(100,100,100,0.2), 0 1px 1px rgba(255,255,255,0.2);\n",
    "   -webkit-transition: box-shadow .5s ease;\n",
    "  -moz-transition: box-shadow .5s ease;\n",
    "   -o-transition: box-shadow .5s ease;\n",
    "    -ms-transition: box-shadow .5s ease;\n",
    "    transition: box-shadow .5s ease;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21d4958",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
